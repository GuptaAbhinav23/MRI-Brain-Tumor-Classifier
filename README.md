# ğŸ§  Brain Tumor Segmentation using Multi-Modal MRI

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![Flask](https://img.shields.io/badge/Flask-2.3+-green.svg)](https://flask.palletsprojects.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A complete end-to-end deep learning system for automated brain tumor segmentation from MRI scans using a 2D U-Net architecture with attention mechanisms.

<p align="center">
  <img src="docs/demo.gif" alt="Brain Tumor Segmentation Demo" width="800">
</p>

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Architecture](#-architecture)
- [Dataset](#-dataset)
- [Installation](#-installation)
- [Training](#-training)
- [Web Application](#-web-application)
- [Deployment](#-deployment)
- [Results](#-results)
- [Project Structure](#-project-structure)
- [API Reference](#-api-reference)
- [Contributing](#-contributing)
- [License](#-license)

## ğŸ¯ Overview

This project implements an automated brain tumor segmentation system using deep learning. It processes multi-modal MRI scans (T1, T1-contrast enhanced, T2, and FLAIR) to identify and segment tumor regions, providing clinicians with a valuable tool for diagnosis assistance.

### Key Highlights

- **State-of-the-art U-Net architecture** with attention gates for improved segmentation
- **Multi-modal MRI support** (FLAIR, T1, T1ce, T2)
- **Production-ready Flask web application** with modern UI
- **Patient-wise data splitting** to prevent data leakage
- **Comprehensive evaluation metrics** (Dice, IoU, Sensitivity, Specificity)

## âœ¨ Features

### Machine Learning
- 2D U-Net with optional attention mechanism
- Combined BCE + Dice loss for optimal training
- Mixed precision training (AMP) for faster training
- Learning rate scheduling with early stopping
- Comprehensive data augmentation

### Web Application
- Drag-and-drop MRI image upload
- Real-time tumor segmentation
- Confidence score visualization
- Overlay visualization of detected tumors
- Responsive, modern medical UI

### Production Ready
- Modular, well-documented code
- Docker support
- Multiple deployment options (Render, Railway, Localhost)

## ğŸ— Architecture

### U-Net with Attention

```
Input (4ch, 128x128)
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Encoder Path   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv Block (64)  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MaxPool          â”‚                           â”‚
â”‚ Conv Block (128) â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚ MaxPool          â”‚                     â”‚     â”‚
â”‚ Conv Block (256) â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚     â”‚
â”‚ MaxPool          â”‚               â”‚     â”‚     â”‚
â”‚ Conv Block (512) â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚     â”‚     â”‚
â”‚ MaxPool          â”‚         â”‚     â”‚     â”‚     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚     â”‚     â”‚     â”‚
       â”‚                     â”‚     â”‚     â”‚     â”‚
       â–¼                     â”‚     â”‚     â”‚     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚     â”‚     â”‚     â”‚
â”‚   Bottleneck     â”‚         â”‚     â”‚     â”‚     â”‚
â”‚ Conv Block (1024)â”‚         â”‚     â”‚     â”‚     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚     â”‚     â”‚     â”‚
       â”‚                     â”‚     â”‚     â”‚     â”‚
       â–¼                     â–¼     â–¼     â–¼     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Decoder Path   â”‚    â”‚  Attention Gates    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚  (Skip Connections) â”‚
â”‚ UpConv + Concat  â”‚â—„â”€â”€â”€â”‚                     â”‚
â”‚ Conv Block (512) â”‚    â”‚                     â”‚
â”‚ UpConv + Concat  â”‚â—„â”€â”€â”€â”‚                     â”‚
â”‚ Conv Block (256) â”‚    â”‚                     â”‚
â”‚ UpConv + Concat  â”‚â—„â”€â”€â”€â”‚                     â”‚
â”‚ Conv Block (128) â”‚    â”‚                     â”‚
â”‚ UpConv + Concat  â”‚â—„â”€â”€â”€â”‚                     â”‚
â”‚ Conv Block (64)  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Output Layer   â”‚
â”‚ Conv 1x1 (1ch)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
Output (1ch, 128x128)
```

## ğŸ“Š Dataset

This project uses the **BraTS 2020** (Brain Tumor Segmentation Challenge) dataset.

### Dataset Structure
```
MICCAI_BraTS2020_TrainingData/
â”œâ”€â”€ BraTS20_Training_001/
â”‚   â”œâ”€â”€ BraTS20_Training_001_flair.nii
â”‚   â”œâ”€â”€ BraTS20_Training_001_t1.nii
â”‚   â”œâ”€â”€ BraTS20_Training_001_t1ce.nii
â”‚   â”œâ”€â”€ BraTS20_Training_001_t2.nii
â”‚   â””â”€â”€ BraTS20_Training_001_seg.nii
â”œâ”€â”€ BraTS20_Training_002/
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

### MRI Modalities
| Modality | Description |
|----------|-------------|
| FLAIR | Fluid Attenuated Inversion Recovery - highlights edema |
| T1 | Standard T1-weighted MRI |
| T1ce | T1 with contrast enhancement - highlights tumor core |
| T2 | T2-weighted MRI - sensitive to edema |

### Segmentation Labels
| Label | Description |
|-------|-------------|
| 0 | Background |
| 1 | Necrotic/Non-enhancing tumor core |
| 2 | Peritumoral edema |
| 4 | GD-enhancing tumor |

## ğŸ’» Installation

### Prerequisites
- Python 3.8+
- CUDA-capable GPU (recommended)
- 8GB+ RAM

### Setup

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/brain-tumor-segmentation.git
cd brain-tumor-segmentation
```

2. **Create virtual environment**
```bash
python -m venv venv

# Windows
.\venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Download the dataset**
   - Register at [CBICA Image Processing Portal](https://www.med.upenn.edu/cbica/brats2020/registration.html)
   - Download BraTS 2020 Training Data
   - Extract to `data/` directory

## ğŸš€ Training

### Quick Start

```bash
cd model
python train.py --data_dir ../data/MICCAI_BraTS2020_TrainingData --epochs 20
```

### Training Options

```bash
python train.py \
    --data_dir PATH_TO_DATA \
    --output_dir outputs \
    --epochs 20 \
    --batch_size 8 \
    --lr 1e-4 \
    --img_size 128 \
    --in_channels 4 \
    --patience 10 \
    --seed 42
```

### Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--data_dir` | Required | Path to BraTS dataset |
| `--output_dir` | `outputs` | Directory for checkpoints |
| `--epochs` | 20 | Number of training epochs |
| `--batch_size` | 8 | Batch size |
| `--lr` | 1e-4 | Learning rate |
| `--img_size` | 128 | Input image size |
| `--in_channels` | 4 | Number of MRI modalities |
| `--no_attention` | False | Disable attention gates |
| `--no_amp` | False | Disable mixed precision |
| `--patience` | 10 | Early stopping patience |

### Training Output
- `model.pth` - Best model checkpoint
- `training_history.png` - Loss and Dice curves
- `results.pth` - Full training results

## ğŸŒ Web Application

### Running Locally

```bash
# From project root
python app.py
```

Visit `http://localhost:5000` in your browser.

### Using with Trained Model

```bash
# Set model path environment variable
set MODEL_PATH=outputs/run_XXXXXXXX/model.pth  # Windows
export MODEL_PATH=outputs/run_XXXXXXXX/model.pth  # Linux/Mac

python app.py
```

### Web Interface Features

1. **Upload**: Drag & drop or click to upload MRI image
2. **Analyze**: Process image through the neural network
3. **Results**: View segmentation results with:
   - Original image
   - Predicted mask
   - Overlay visualization
   - Confidence score
   - Tumor coverage percentage

## ğŸš¢ Deployment

### Option 1: Render

1. Create `render.yaml`:
```yaml
services:
  - type: web
    name: brain-tumor-segmentation
    env: python
    buildCommand: pip install -r requirements.txt
    startCommand: gunicorn app:app --bind 0.0.0.0:$PORT
```

2. Push to GitHub
3. Connect repository in Render dashboard
4. Deploy!

### Option 2: Railway

1. Install Railway CLI:
```bash
npm install -g @railway/cli
railway login
```

2. Deploy:
```bash
railway init
railway up
```

### Option 3: Docker

```dockerfile
FROM python:3.10-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .
EXPOSE 5000

CMD ["gunicorn", "app:app", "--bind", "0.0.0.0:5000"]
```

```bash
docker build -t brain-tumor-seg .
docker run -p 5000:5000 brain-tumor-seg
```

### Option 4: Localhost with Waitress (Production WSGI)

```bash
pip install waitress
waitress-serve --port=5000 app:app
```

## ğŸ“ˆ Results

### Model Performance

| Metric | Value |
|--------|-------|
| Dice Score | 0.85+ |
| IoU | 0.75+ |
| Sensitivity | 0.88+ |
| Specificity | 0.98+ |
| Pixel Accuracy | 0.97+ |

### Training Curves

The model typically converges within 15-20 epochs with the following characteristics:
- Rapid initial learning (epochs 1-5)
- Gradual refinement (epochs 5-15)
- Plateau with best model selection

## ğŸ“ Project Structure

```
brain_tumor_project/
â”‚
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ __init__.py          # Package init
â”‚   â”œâ”€â”€ unet.py               # U-Net architecture
â”‚   â”œâ”€â”€ dataset.py            # Data loading & preprocessing
â”‚   â”œâ”€â”€ train.py              # Training pipeline
â”‚   â””â”€â”€ utils.py              # Loss, metrics, visualization
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html            # Web interface template
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css             # UI styling
â”‚   â””â”€â”€ script.js             # Frontend JavaScript
â”‚
â”œâ”€â”€ app.py                    # Flask application
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ model.pth                 # Trained model (after training)
â””â”€â”€ outputs/                  # Training outputs
```

## ğŸ”Œ API Reference

### Endpoints

#### `GET /`
Serves the web interface.

#### `GET /health`
Health check endpoint.

**Response:**
```json
{
    "status": "healthy",
    "model_loaded": true,
    "device": "cuda",
    "timestamp": "2026-02-24T12:00:00.000Z"
}
```

#### `POST /predict`
Analyze uploaded MRI image.

**Request:**
- Content-Type: `multipart/form-data`
- Body: `file` - Image file (PNG, JPG, etc.)

**Response:**
```json
{
    "success": true,
    "tumor_detected": true,
    "confidence": 0.8532,
    "confidence_percent": 85.32,
    "tumor_ratio": 0.0523,
    "tumor_ratio_percent": 5.23,
    "original_image": "data:image/png;base64,...",
    "mask_image": "data:image/png;base64,...",
    "overlay_image": "data:image/png;base64,..."
}
```

#### `GET /model-info`
Get model information.

**Response:**
```json
{
    "loaded": true,
    "architecture": "U-Net with Attention",
    "input_channels": 4,
    "input_size": "128x128",
    "total_parameters": 31234567,
    "trainable_parameters": 31234567,
    "threshold": 0.5,
    "device": "cuda"
}
```

## ğŸ›¡ï¸ Medical Disclaimer

âš ï¸ **Important**: This tool is designed for **research and educational purposes only**. It should **NOT** be used as a substitute for professional medical diagnosis, treatment, or advice. Always consult qualified healthcare professionals for medical decisions.

## ğŸ”¬ Technical Details

### Preprocessing Pipeline
1. Load NIfTI files using `nibabel`
2. Extract 2D slices from 3D volumes
3. Z-score normalization per slice
4. Resize to 128Ã—128
5. Stack multi-modal inputs

### Patient-wise Splitting
To prevent data leakage, the dataset is split by patient:
- **Training**: 70% of patients
- **Validation**: 15% of patients
- **Testing**: 15% of patients

All slices from a single patient belong to the same split.

### Data Augmentation
- Random horizontal flip
- Random vertical flip
- Random 90Â° rotations

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [BraTS Challenge](http://braintumorsegmentation.org/) for the dataset
- [U-Net Paper](https://arxiv.org/abs/1505.04597) by Ronneberger et al.
- [Attention U-Net Paper](https://arxiv.org/abs/1804.03999) by Oktay et al.
- PyTorch and Flask communities

## ğŸ“§ Contact

For questions or support, please open an issue on GitHub.

---

<p align="center">
  Made with â¤ï¸ for Medical AI Research
</p>

